{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4u1nPDMhtVuD"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xzvd8w17tXw4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>ache</th>\n",
       "      <th>act</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>addict</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>...</th>\n",
       "      <th>you so</th>\n",
       "      <th>you so much</th>\n",
       "      <th>you think</th>\n",
       "      <th>you to</th>\n",
       "      <th>you too</th>\n",
       "      <th>you ve</th>\n",
       "      <th>you want</th>\n",
       "      <th>you were</th>\n",
       "      <th>you will</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  able  absolutely  account  ache  act  actually  add  addict  \\\n",
       "0           0     0           0        0     0    0         0    0       0   \n",
       "1           1     0           0        0     0    0         0    0       0   \n",
       "2           2     0           0        0     0    0         0    0       0   \n",
       "3           3     0           0        0     0    0         0    0       0   \n",
       "4           4     0           0        0     0    0         0    0       0   \n",
       "\n",
       "   afternoon  ...  you so  you so much  you think  you to  you too  you ve  \\\n",
       "0          0  ...       0            0          0       0        0       0   \n",
       "1          0  ...       0            0          0       0        0       0   \n",
       "2          0  ...       0            0          0       0        0       0   \n",
       "3          0  ...       0            0          0       0        0       0   \n",
       "4          0  ...       0            0          0       0        0       0   \n",
       "\n",
       "   you want  you were  you will  Sentiment  \n",
       "0         0         0         0          1  \n",
       "1         0         0         0          1  \n",
       "2         0         0         0          0  \n",
       "3         0         0         0          1  \n",
       "4         0         0         0          1  \n",
       "\n",
       "[5 rows x 2002 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv('vectorized.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>account</th>\n",
       "      <th>ache</th>\n",
       "      <th>act</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>addict</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>you so</th>\n",
       "      <th>you so much</th>\n",
       "      <th>you think</th>\n",
       "      <th>you to</th>\n",
       "      <th>you too</th>\n",
       "      <th>you ve</th>\n",
       "      <th>you want</th>\n",
       "      <th>you were</th>\n",
       "      <th>you will</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  account  ache  act  actually  add  addict  afternoon  \\\n",
       "0     0           0        0     0    0         0    0       0          0   \n",
       "1     0           0        0     0    0         0    0       0          0   \n",
       "2     0           0        0     0    0         0    0       0          0   \n",
       "3     0           0        0     0    0         0    0       0          0   \n",
       "4     0           0        0     0    0         0    0       0          0   \n",
       "\n",
       "   age  ...  you so  you so much  you think  you to  you too  you ve  \\\n",
       "0    0  ...       0            0          0       0        0       0   \n",
       "1    0  ...       0            0          0       0        0       0   \n",
       "2    0  ...       0            0          0       0        0       0   \n",
       "3    0  ...       0            0          0       0        0       0   \n",
       "4    0  ...       0            0          0       0        0       0   \n",
       "\n",
       "   you want  you were  you will  Sentiment  \n",
       "0         0         0         0          1  \n",
       "1         0         0         0          1  \n",
       "2         0         0         0          0  \n",
       "3         0         0         0          1  \n",
       "4         0         0         0          1  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data['Unnamed: 0']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['Sentiment']\n",
    "del train_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        able  absolutely  account  ache  act  actually  add  addict  \\\n",
      "311902     0           0        0     0    0         0    0       0   \n",
      "477285     0           0        0     0    0         0    0       0   \n",
      "74015      0           0        0     0    0         0    0       0   \n",
      "110640     0           0        0     0    0         0    0       0   \n",
      "355508     0           0        0     0    0         0    0       0   \n",
      "...      ...         ...      ...   ...  ...       ...  ...     ...   \n",
      "649926     0           0        0     0    0         0    0       0   \n",
      "591846     0           0        0     0    0         0    0       0   \n",
      "883044     0           0        0     0    0         0    0       0   \n",
      "230386     0           0        0     0    0         0    0       0   \n",
      "307673     0           0        0     0    0         0    0       0   \n",
      "\n",
      "        afternoon  age  ...  you should  you so  you so much  you think  \\\n",
      "311902          0    0  ...           0       0            0          0   \n",
      "477285          0    0  ...           0       0            0          0   \n",
      "74015           0    0  ...           0       0            0          0   \n",
      "110640          0    0  ...           0       0            0          0   \n",
      "355508          0    0  ...           0       0            0          0   \n",
      "...           ...  ...  ...         ...     ...          ...        ...   \n",
      "649926          0    0  ...           0       0            0          0   \n",
      "591846          0    0  ...           0       0            0          0   \n",
      "883044          0    0  ...           0       0            0          0   \n",
      "230386          0    0  ...           0       0            0          0   \n",
      "307673          0    0  ...           0       0            0          0   \n",
      "\n",
      "        you to  you too  you ve  you want  you were  you will  \n",
      "311902       0        0       0         0         0         0  \n",
      "477285       0        0       0         0         0         0  \n",
      "74015        0        0       0         0         0         0  \n",
      "110640       0        0       0         0         0         0  \n",
      "355508       0        0       0         0         0         0  \n",
      "...        ...      ...     ...       ...       ...       ...  \n",
      "649926       0        0       0         0         0         0  \n",
      "591846       0        0       0         0         0         0  \n",
      "883044       0        0       0         0         0         0  \n",
      "230386       0        0       0         0         0         0  \n",
      "307673       0        0       0         0         0         0  \n",
      "\n",
      "[800000 rows x 2000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " ...\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]]\n"
     ]
    }
   ],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05871238 26.12969059 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " ...\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]\n",
      " [-0.05871238 -0.03800858 -0.04713785 ... -0.03990767 -0.04927932\n",
      "  -0.03912438]]\n"
     ]
    }
   ],
   "source": [
    "X_test = scaler.transform(X_test)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3FHF6Nio2niR",
    "outputId": "ba15dc1c-29ec-4970-aa72-55047b0d54d4"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(max_iter=300)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gXYdZO9R2rxT",
    "outputId": "d908e440-3e80-4379-c18b-71b3acc5be4c"
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judging = pd.read_csv('contestant_judgment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words contains typical sentence stopping words from the english language\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# contains all the filtered (good) words\n",
    "filtered_sent = []\n",
    "\n",
    "for index, row in judging.iterrows():\n",
    "    tokenized_words = []\n",
    "    # Remove @s\n",
    "    judging.at[index, 'Text'] = re.sub(r\"@[A-z]+\", \" \", judging.at[index, 'Text'])\n",
    "    \n",
    "    # Remove punctuation\n",
    "    judging.at[index, 'Text'] = re.sub(r\"\\W\", \" \", judging.at[index, 'Text'])\n",
    "\n",
    "    # Remove numbers\n",
    "    judging.at[index, 'Text'] = re.sub(r\"\\d+\", \"\", judging.at[index, 'Text'])\n",
    "\n",
    "    # Remove spaces\n",
    "    judging.at[index, 'Text'] = re.sub(r\"\\s+\", \" \", judging.at[index, 'Text'])\n",
    "   \n",
    "    # Make everything lowercase\n",
    "    judging.at[index, 'Text'] = str(judging.at[index, 'Text']).lower()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokenized_words = nltk.word_tokenize(judging.at[index, 'Text'])\n",
    "    \n",
    "    # Appending all the filtered words to filtered_sent\n",
    "    filtered_sent.append([])\n",
    "    for w in tokenized_words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent[index].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting lemmatizer from nltk library\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# looping through filtered_sent and lemmatizing each of the words\n",
    "# lemmatizing means to sort words with similar stem or form\n",
    "i = 0\n",
    "for words in filtered_sent:\n",
    "    newWords = []\n",
    "\n",
    "    # Lemmatizing the words in each list of filtered words\n",
    "    for word in words:\n",
    "        newWords.append(lemmatizer.lemmatize(word, pos = 'v'))\n",
    "     \n",
    "    # putting the lemmatized words back in the filtered_send list\n",
    "    filtered_sent[i] = \" \".join(newWords)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judging['BagofWords'] = filtered_sent\n",
    "# creating original features, next step is vectorization\n",
    "bagofwords = judging.BagofWords.tolist()\n",
    "\n",
    "# creating a CountVectorizer for 400 single-word phrases\n",
    "cv = CountVectorizer(max_features=400)\n",
    "\n",
    "# creating a CountVectorizer for 400 two or three-word phrases phrases\n",
    "cv2 = CountVectorizer(max_features=400, ngram_range=(2, 3))\n",
    "\n",
    "# concatenating the arrays that have formed small vectors to get a large feature vector\n",
    "x = np.concatenate((cv.fit_transform(judging['BagofWords']).toarray(), cv2.fit_transform(judging['Text']).toarray()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = classifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judging['Sentiment'] = test_predictions\n",
    "judging.to_csv('judging.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BE3gRLN-Uzh"
   },
   "source": [
    "# Neural Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMgxM6nA22HD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THko5Bk13l-n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               384256    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                204       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 430,941\n",
      "Trainable params: 430,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=256, input_shape=X_train[0].shape, activation='relu'))\n",
    "model.add(Dense(units=128, activation=None))\n",
    "model.add(Dense(units=64, activation=None))\n",
    "model.add(Dense(units=48, activation=None))\n",
    "model.add(Dense(units=32, activation=None))\n",
    "model.add(Dense(units=16, activation=None))\n",
    "model.add(Dense(units=12, activation=None))\n",
    "model.add(Dense(units=8, activation=None))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pjeOUYe54IHi",
    "outputId": "30e0f5f6-1856-4b5d-b228-91374ed57a4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "94783lOJ9JOQ",
    "outputId": "01c728db-c69a-4430-a94e-dd8411714ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05847612, -0.03774496, -0.04617577, ..., -0.04015807,\n",
       "       -0.04983262, -0.0383099 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "0Rd1wXz03uvH",
    "outputId": "c120820c-6093-413c-9968-8cafa103371d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.5013 - accuracy: 0.7538\n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.4819 - accuracy: 0.7668\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.4711 - accuracy: 0.7740\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 94s 4ms/step - loss: 0.4586 - accuracy: 0.7818\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 93s 4ms/step - loss: 0.4419 - accuracy: 0.7917\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.4229 - accuracy: 0.8025\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 73s 3ms/step - loss: 0.4046 - accuracy: 0.8124\n",
      "Epoch 8/30\n",
      "25000/25000 [==============================] - 71s 3ms/step - loss: 0.3868 - accuracy: 0.8217\n",
      "Epoch 9/30\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.3697 - accuracy: 0.8306\n",
      "Epoch 10/30\n",
      "25000/25000 [==============================] - 72s 3ms/step - loss: 0.3540 - accuracy: 0.8385\n",
      "Epoch 11/30\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.3389 - accuracy: 0.8459A: 55s - loss: 0.3206 - accuracy: 0.8 - ETA: 54s - loss: 0.3207 - accu - ETA: 54s - loss: 0.3211 - accuracy: - ETA: 53s - l\n",
      "Epoch 12/30\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.3251 - accuracy: 0.8528A: 52s - loss: 0.3090 - accuracy: 0.8 - ETA: 52s - loss: 0.3090  - ETA: 51s - loss: 0.3097 - ETA: 47s -  - ETA: 4 - ETA: 44s - loss: 0 - - ETA: 0s - loss: 0.3249 - accuracy - ETA: 0s - los\n",
      "Epoch 13/30\n",
      "25000/25000 [==============================] - 79s 3ms/step - loss: 0.3126 - accuracy: 0.8590A: 59s - loss: 0.2932 - accuracy: 0.8 - ETA:\n",
      "Epoch 14/30\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.3018 - accuracy: 0.8640\n",
      "Epoch 15/30\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.2914 - accuracy: 0.8691\n",
      "Epoch 16/30\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.2817 - accuracy: 0.8743A: 57s - loss: 0.2616 - accur - ETA: 56s - loss: 0.2614 - ac - ETA: 55s - loss: 0. - - ETA: 51s -  - ETA: 37s - loss: 0 - - ETA: - ETA: 30s - loss: 0.2720 - accura - ETA: 29s - loss: 0.2723 - ac - ETA: 28s - l - ETA: 27s - - ETA: 25s - loss: 0.2734 - accu - ETA: 25s - loss: 0.2 - ETA: 21s - loss - ETA: 0s - loss: 0.2816 - accuracy: 0.\n",
      "Epoch 17/30\n",
      "25000/25000 [==============================] - 76s 3ms/step - loss: 0.2733 - accuracy: 0.8780A: 52s - los\n",
      "Epoch 18/30\n",
      "25000/25000 [==============================] - 76s 3ms/step - loss: 0.2652 - accuracy: 0.8815A: 24s - loss: 0.2580 - ac\n",
      "Epoch 19/30\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2582 - accuracy: 0.8850\n",
      "Epoch 20/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2510 - accuracy: 0.8881\n",
      "Epoch 21/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2449 - accuracy: 0.8911\n",
      "Epoch 22/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2389 - accuracy: 0.8940A: 0s - loss: 0.2388 - \n",
      "Epoch 23/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2330 - accuracy: 0.8965\n",
      "Epoch 24/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2284 - accuracy: 0.8985  - ETA: 1s -\n",
      "Epoch 25/30\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.2234 - accuracy: 0.9014 0s - loss: 0.2232 - accu\n",
      "Epoch 26/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2188 - accuracy: 0.9029\n",
      "Epoch 27/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2152 - accuracy: 0.9052\n",
      "Epoch 28/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2108 - accuracy: 0.9070\n",
      "Epoch 29/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2071 - accuracy: 0.9082 5s - los\n",
      "Epoch 30/30\n",
      "25000/25000 [==============================] - 59s 2ms/step - loss: 0.2038 - accuracy: 0.9099\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mDnnPCD5FNA"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yn8ZKIBG5uga",
    "outputId": "5603c660-2c0a-44b3-a5a3-a024ec9d231f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38386053], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for pred in preds:\n",
    "    if pred[0] < 0.5:\n",
    "        predicts.append(0)\n",
    "    else: \n",
    "        predicts.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(predicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727645"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "finalmodel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
